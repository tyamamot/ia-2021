{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 潜在的意味解析\n",
    " - このノートブックは講義で扱った潜在的意味解析（LSA）の理解を補助するノートブックです\n",
    "   - 個々の計算などはこの講義では理解する必要はありません．興味のある人の参考になれば幸いです．\n",
    " - 参考文献: Christopher D. Manning et al., [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/), Cambridge University Press. 2008.\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as lg\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%precision 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(v1,v2): #コサイン類似度\n",
    "    return 1-cosine(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 講義資料の内容を用意\n",
    "M = np.array(\n",
    "    [[1,0,1,0,0,0],\n",
    "    [0,1,0,0,0,0],\n",
    "    [1,1,0,0,0,0],\n",
    "    [1,0,0,1,1,0],\n",
    "    [0,0,0,1,0,1]]\n",
    ")\n",
    "print(M)\n",
    "print(M.shape)\n",
    "print(\"Rank(M) =\", np.linalg.matrix_rank(M)) #行列Mのランクは5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_names = [\"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\"]\n",
    "term_names = [\"ship\", \"boat\", \"ocean\", \"voyge\", \"trip\"]\n",
    "df = pd.DataFrame(M, \n",
    "                  columns=doc_names, index=term_names) \n",
    "df # 単語-文書行列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特異値分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, sigma, Vt = lg.svd(M) #SVD．なお，sigmaは行列ではなく特異値が降順に並んだ配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sigma = lg.diagsvd(sigma, M.shape[0], M.shape[1]) #確認のため truncateしていないSigmaを作成する．特異値集合からMxN対角行列を作成する．\n",
    "\n",
    "print(Sigma.shape)\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "M_r = np.dot(np.dot(U, Sigma), Vt) #分解した結果が本当にMと一致するのか確認 M = U x Sigma x V^T\n",
    "print(\"{:.2f}\".format(np.linalg.norm(M - M_r))) #　元の行列と分解結果の差のフロベニウスノルム　（各要素の二乗和の平方根）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 低ランク近似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2 #次元数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_k = U[:, :k] #m-k行列にカット\n",
    "Vt_k = Vt[:k,:] #k-n行列にカット\n",
    "Sigma_k = Sigma[:k,:k] #特異値上位k個のみを用いる\n",
    "print(\"U_k =\"),\n",
    "print(U_k)\n",
    "print(\"Sigma_k=\")\n",
    "print(Sigma_k)\n",
    "print(\"V_k^T =\"),\n",
    "print(Vt_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "M_k = np.dot(np.dot(U_k, Sigma_k), Vt_k) #低ランク近似\n",
    "print(\"M_k=\")\n",
    "print(M_k)\n",
    "doc_names = [\"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\"]\n",
    "term_names = [\"ship\", \"boat\", \"ocean\", \"voyge\", \"trip\"]\n",
    "df = pd.DataFrame(M_k, \n",
    "                  columns=doc_names, index=term_names) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"|| M - M_k || =\", lg.norm(M-M_k)) # フロベニウスノルム\n",
    "print(\"Rank(M_k) =\", np.linalg.matrix_rank(M_k)) #ランク2の行列になっていることを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lg.norm(M-M_k)**2) # フロベニウスノルムの二乗が，k+1以降の特異値の平方和に等しいことを確認\n",
    "print(sum(map(lambda x: x ** 2, sigma[k:]))) # k+1以降の特異値の平方和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文書ベクトルの次元削減\n",
    "\n",
    "$M_k = U_k \\Sigma_k V_t^T$\n",
    "\n",
    "$M_k$は$m\\times n$行列であった．これを，特徴-文書，つまり$k \\times n$行列で表現することを考える．\n",
    "\n",
    "両辺に左から$U_k^T$を掛けると， \n",
    "\n",
    "$U_k^T M_k  = \\Sigma_k V_k^T$ \n",
    "\n",
    "ここで，$U_k U_k^T=I$を利用した（$U$が正規直交行列のため）．\n",
    "\n",
    "$U_k^T M_k=D_k = ({\\bf d}_1^{(k)}, \\ldots, {\\bf d}_n^{(k)})$とおくと，\n",
    "\n",
    "$D_k = \\Sigma_k V_k^T  $\n",
    "\n",
    "${\\bf d}_i^{(k)}$を特徴空間上での文書ベクトルとして利用することができる．　なお， ${\\bf d}_{i}^{(k)}$ は ${\\bf d}_{i}^{(k)} = U_k^T {\\bf d}_j$としても求められる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_k = np.dot(Sigma_k, Vt_k)\n",
    "D_k\n",
    "axis_names = [\"z1\", \"z2\"]\n",
    "doc_names = [\"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\"]\n",
    "df = pd.DataFrame(D_k.T, \n",
    "                  columns=axis_names, index=doc_names) # np.r_ は行列同士の連結\n",
    "print(\"D_k=\")\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.plot.scatter(x=\"z1\", y=\"z2\", ax=ax)\n",
    "ax.axvline(x=0, lw=2, color='red') #x軸とy軸に線を引く\n",
    "ax.axhline(y=0, lw=2, color='red') \n",
    "ax.set_xlim(-0.5, 2.0)\n",
    "ax.set_ylim(-1.0, 1.5)\n",
    "ax.grid(True)\n",
    "for k, v in df.iterrows():\n",
    "    ax.annotate(k, xy=(v[0]+0.05,v[1]+0.05),size=15) #データ点にラベル名を付与"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文書$d1$と$d2$の特徴空間上での類似度を計算してみよう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1とd2の特徴空間上での類似度を計算する\n",
    "print(\"特徴空間上でのコサイン類似度 =\",sim(D_k[:,0], D_k[:,1]))\n",
    "print(\"M_k上での文書ベクトルのコサイン類似度 =\", sim(M_k[:,0], M_k[:,1]))\n",
    "print(\"なお，元の文書ベクトル上でのコサイン類似度 =\", sim(M[:,0],M[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように，次元削減された文書ベクトル$\\{{\\bf d}_i^{(k)}\\}$間のコサイン類似度が，低ランク近似された単語-文書行列$M_k$における文書ベクトル間のコサイン類似度と一致することが分かる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クエリの特徴空間での表現\n",
    "\n",
    "いま，$m$次元クエリべトル${\\bf q}$が与えられたとき，特徴空間上でのベクトル表現${\\bf q}^{(k)}$は以下の式で得られる．\n",
    "\n",
    "${\\bf q}^{(k)} = U_k^T {\\bf q}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([1,0,1,1,0]) #文書d1と同じものをクエリとして用いてみる\n",
    "q_k = np.dot(U_k.T, q)  #k次元特徴空間へ射影\n",
    "print(q_k) # d_j^{k} と一致していることを確認\n",
    "print(\"sim(q, d) =\",sim(q_k, D_k[:,0])) #文書d1との特徴空間上での類似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語ベクトルの次元削減\n",
    "\n",
    "$M_k = U_k \\Sigma_k V_t^T$\n",
    "\n",
    "文書ベクトルと同様に，今度は両辺に右から$V_k$をかけると\n",
    "\n",
    "$M_k V_k = U_k \\Sigma_k$ （$V_k^T V_k=I$より)\n",
    "\n",
    "$U_k \\Sigma_k =T_k $とおくと，\n",
    "\n",
    "$T_k = U_k \\Sigma_k$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T_k  = np.dot(U_k, Sigma_k)\n",
    "axis_names = [\"z1\", \"z2\"]\n",
    "term_names = [\"ship\", \"boat\", \"ocean\", \"voyge\", \"trip\"]\n",
    "df = pd.DataFrame(T_k, \n",
    "                  columns=axis_names, index=term_names) # np.r_ は行列同士の連結\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T$の$i$行目と$j$行目がそれぞれ単語$i，j$の特徴空間上でのベクトル表現になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴空間上の単語ベクトルをプロット\n",
    "fig, ax = plt.subplots()\n",
    "df.plot.scatter(x=\"z1\", y=\"z2\", ax=ax)\n",
    "ax.axvline(x=0, lw=2, color='red') #x軸とy軸に線を引く\n",
    "ax.axhline(y=0, lw=2, color='red') \n",
    "ax.set_xlim(-0.5, 2.0)\n",
    "ax.set_ylim(-1.0, 1.5)\n",
    "ax.grid(True)\n",
    "for k, v in df.iterrows():\n",
    "    ax.annotate(k, xy=(v[0]+0.05,v[1]+0.05),size=15) #データ点にラベル名を付与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_1 = T_k[0,:] #ship\n",
    "t_2 = T_k[1,:] #boat\n",
    "\n",
    "print(\"k次元特徴空間での類似度\")\n",
    "print(\"sim(ship, boat) =\", sim(t_1, t_2))\n",
    "print(\"元の空間での類似度\")\n",
    "print(\"sim(ship, boat) =\", sim(M[0,:], M[1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように，元の単語-文書行列における単語ベクトルでは類似度が0であった単語間に対して高い類似度を与えることができていることが分かる．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
